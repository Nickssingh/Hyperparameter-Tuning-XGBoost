{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparamter Tuning - XGBoost\n",
    "\n",
    "# Here is the highlight of the process\n",
    "# 1. Import the customer churn data (I have already cleaned it)\n",
    "# 2. Split the data into test and train sets\n",
    "# 3. Build data matrices - as XGBoost uses DMatrix\n",
    "# 4. Find the logloss of the model with default parameters\n",
    "# 5. Tune the parameters\n",
    "# 6. Find the logloss of the model with tuned parameters\n",
    "\n",
    "# For exploratory analysis and other models on this dataset, please use the following link\n",
    "# https://github.com/Nickssingh/Churn-Prediction-Model-Telecommunication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will import the dataset and view top rows\n",
    "# I have already preapared the the data for analysis \n",
    "    # Removed the missing values\n",
    "    # Converted the variables into appropriate data types\n",
    "    # Encoded categorical variables using one hot encoding\n",
    "\n",
    "df_churn=pd.read_csv(\"https://github.com/Nickssingh/Hyperparameter-tuning-XGBoost/raw/master/Data/telcom_customer_churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>Partner_Yes</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>PhoneService_Yes</th>\n",
       "      <th>MultipleLines_No phone service</th>\n",
       "      <th>...</th>\n",
       "      <th>StreamingTV_No internet service</th>\n",
       "      <th>StreamingTV_Yes</th>\n",
       "      <th>StreamingMovies_No internet service</th>\n",
       "      <th>StreamingMovies_Yes</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaperlessBilling_Yes</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeniorCitizen  tenure  MonthlyCharges  TotalCharges  Churn  gender_Male  \\\n",
       "0              0       1           29.85         29.85      0            0   \n",
       "1              0      34           56.95       1889.50      0            1   \n",
       "2              0       2           53.85        108.15      1            1   \n",
       "3              0      45           42.30       1840.75      0            1   \n",
       "4              0       2           70.70        151.65      1            0   \n",
       "\n",
       "   Partner_Yes  Dependents_Yes  PhoneService_Yes  \\\n",
       "0            1               0                 0   \n",
       "1            0               0                 1   \n",
       "2            0               0                 1   \n",
       "3            0               0                 0   \n",
       "4            0               0                 1   \n",
       "\n",
       "   MultipleLines_No phone service             ...              \\\n",
       "0                               1             ...               \n",
       "1                               0             ...               \n",
       "2                               0             ...               \n",
       "3                               1             ...               \n",
       "4                               0             ...               \n",
       "\n",
       "   StreamingTV_No internet service  StreamingTV_Yes  \\\n",
       "0                                0                0   \n",
       "1                                0                0   \n",
       "2                                0                0   \n",
       "3                                0                0   \n",
       "4                                0                0   \n",
       "\n",
       "   StreamingMovies_No internet service  StreamingMovies_Yes  \\\n",
       "0                                    0                    0   \n",
       "1                                    0                    0   \n",
       "2                                    0                    0   \n",
       "3                                    0                    0   \n",
       "4                                    0                    0   \n",
       "\n",
       "   Contract_One year  Contract_Two year  PaperlessBilling_Yes  \\\n",
       "0                  0                  0                     1   \n",
       "1                  1                  0                     0   \n",
       "2                  0                  0                     1   \n",
       "3                  1                  0                     0   \n",
       "4                  0                  0                     1   \n",
       "\n",
       "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "0                                      0                               1   \n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               1   \n",
       "\n",
       "   PaymentMethod_Mailed check  \n",
       "0                           0  \n",
       "1                           1  \n",
       "2                           1  \n",
       "3                           0  \n",
       "4                           0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7032, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the dimension of the data\n",
    "\n",
    "df_churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the data into train and test datasets\n",
    "# test:train = 3:7\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "df_temp = df_churn\n",
    "y = df_temp['Churn']\n",
    "X = df_temp.drop('Churn', axis=1, inplace=False)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Requirement already satisfied: xgboost in ./anaconda2/lib/python2.7/site-packages (0.82)\n",
      "Requirement already satisfied: numpy in ./anaconda2/lib/python2.7/site-packages (from xgboost) (1.11.1)\n",
      "Requirement already satisfied: scipy in ./anaconda2/lib/python2.7/site-packages (from xgboost) (0.17.1)\n"
     ]
    }
   ],
   "source": [
    "# Installing XGBoost\n",
    "\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XGBoost uses an internal data structure DMatrix - which optimizes both memory effieciency and speed\n",
    "# Hence, rather than using pandas dataframe, we will use data matrix - DMatrix\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "dm_train = xgb.DMatrix(X_train, label=y_train)\n",
    "dm_test = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building Model\n",
    "\n",
    "# Ideal case would include an exhaustive gridsearch on all the parameters.\n",
    "# However, such an approach is computationally intensive.\n",
    "# Hence, we will focus on few important parameters and tune them sequentially.\n",
    "\n",
    "# Following are the parameters that we will tune in this process\n",
    "# max_depth\n",
    "# min_child_weight\n",
    "# subsample\n",
    "# colsample_bytree\n",
    "# eta\n",
    "# num_boost_rounds\n",
    "# early_stopping_rounds\n",
    "\n",
    "# We will use logistic loss function to assess the accuracy of predictions, as this is a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-logloss:0.581809\n",
      "Will train until Test-logloss hasn't improved in 10 rounds.\n",
      "[1]\tTest-logloss:0.520662\n",
      "[2]\tTest-logloss:0.484648\n",
      "[3]\tTest-logloss:0.459301\n",
      "[4]\tTest-logloss:0.44479\n",
      "[5]\tTest-logloss:0.43489\n",
      "[6]\tTest-logloss:0.428768\n",
      "[7]\tTest-logloss:0.427162\n",
      "[8]\tTest-logloss:0.425635\n",
      "[9]\tTest-logloss:0.423885\n",
      "[10]\tTest-logloss:0.424516\n",
      "[11]\tTest-logloss:0.425703\n",
      "[12]\tTest-logloss:0.426199\n",
      "[13]\tTest-logloss:0.426466\n",
      "[14]\tTest-logloss:0.427974\n",
      "[15]\tTest-logloss:0.428433\n",
      "[16]\tTest-logloss:0.429665\n",
      "[17]\tTest-logloss:0.429645\n",
      "[18]\tTest-logloss:0.42989\n",
      "[19]\tTest-logloss:0.430252\n",
      "Stopping. Best iteration:\n",
      "[9]\tTest-logloss:0.423885\n",
      "\n",
      "Best Logloss: 0.424 | Rounds: 10\n"
     ]
    }
   ],
   "source": [
    "# We will set num_boost_rounds to 100, early_stopping_rounds to 10, and objective to binary:logistic.\n",
    "# All the other values at this stage are default values.\n",
    "# We will tune our model by chaning the default values.\n",
    "\n",
    "params = {'max_depth':6, 'min_child_weight':1, 'eta':0.3, 'subsample':1, \n",
    "          'colsample_bytree':1, 'objective':'binary:logistic',}\n",
    "\n",
    "# We will use logloss function to evaluate the model's performance\n",
    "params['eval_metric'] = \"logloss\"\n",
    "\n",
    "xgmodel = xgb.train(params, dtrain = dm_train, num_boost_round = 100, evals = [(dm_test,\"Test\")], \n",
    "                    early_stopping_rounds = 10)\n",
    "\n",
    "print(\"Best Logloss: {:.3f} | Rounds: {}\".format(xgmodel.best_score,xgmodel.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here, we found that the tenth round gave the best result and the results did not improve in the next 10 rounds\n",
    "# Hence, the iteration stopped at round 19 and we did not reach the maximum number of boosting rounds (100).\n",
    "\n",
    "# Finding a suitable evidence to stop the iterations is important.\n",
    "# Stopping the iterations when results do not improve prevents overfittig and the inefficient utilization of resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will use cross validation to tune the parameters within the params dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters: max-depth and min_child_weight\n",
    "# I realized that the optimal values are in the following ranges through multiple iterations\n",
    "\n",
    "gridsearch_params = [(max_depth, min_child_weight)\n",
    "                    for max_depth in range(1,4)\n",
    "                    for min_child_weight in range(17,21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 1 | min_child_weight: 17 with Logloss: 0.41\n",
      "\n",
      "max_depth: 1 | min_child_weight: 18 with Logloss: 0.41\n",
      "\n",
      "max_depth: 1 | min_child_weight: 19 with Logloss: 0.41\n",
      "\n",
      "max_depth: 1 | min_child_weight: 20 with Logloss: 0.41\n",
      "\n",
      "max_depth: 2 | min_child_weight: 17 with Logloss: 0.41\n",
      "\n",
      "max_depth: 2 | min_child_weight: 18 with Logloss: 0.41\n",
      "\n",
      "max_depth: 2 | min_child_weight: 19 with Logloss: 0.41\n",
      "\n",
      "max_depth: 2 | min_child_weight: 20 with Logloss: 0.41\n",
      "\n",
      "max_depth: 3 | min_child_weight: 17 with Logloss: 0.412\n",
      "\n",
      "max_depth: 3 | min_child_weight: 18 with Logloss: 0.413\n",
      "\n",
      "max_depth: 3 | min_child_weight: 19 with Logloss: 0.413\n",
      "\n",
      "max_depth: 3 | min_child_weight: 20 with Logloss: 0.414\n",
      "\n",
      "Best Parameters: max_depth: 2 | min_child_weight: 19 with Logloss: 0.410\n"
     ]
    }
   ],
   "source": [
    "logloss_min = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    \n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    \n",
    "    xg_cvresults = xgb.cv(params, dtrain = dm_train, num_boost_round = 100,\n",
    "                      seed = 0, nfold=10, metrics = {'logloss'}, early_stopping_rounds = 10,)\n",
    "    \n",
    "    logloss_mean = xg_cvresults['test-logloss-mean'].min()\n",
    "    \n",
    "    print(\"max_depth: {} | min_child_weight: {} with Logloss: {:.3}\\n\".format(max_depth,min_child_weight,logloss_mean))\n",
    "    \n",
    "    if logloss_mean < logloss_min:\n",
    "        logloss_min = logloss_mean\n",
    "        best_params = (max_depth, min_child_weight)\n",
    "\n",
    "        \n",
    "print(\"Best Parameters: max_depth: {} | min_child_weight: {} with Logloss: {:.3f}\". format(best_params[0], \n",
    "                                                                                  best_params[1], logloss_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Updating the parameters with the best values: max_depth = 2 and min_child_weight = 19\n",
    "\n",
    "params['max_depth'] = 2\n",
    "params['min_child_weight'] = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters: subsample and colsample_bytree\n",
    "# I found that the optimal values are in the following ranges through multiple iterations\n",
    "\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(1,5)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsample: 0.7 | colsample: 0.1 with Logloss: 0.412\n",
      "\n",
      "subsample: 0.7 | colsample: 0.2 with Logloss: 0.411\n",
      "\n",
      "subsample: 0.7 | colsample: 0.3 with Logloss: 0.410\n",
      "\n",
      "subsample: 0.7 | colsample: 0.4 with Logloss: 0.411\n",
      "\n",
      "subsample: 0.8 | colsample: 0.1 with Logloss: 0.411\n",
      "\n",
      "subsample: 0.8 | colsample: 0.2 with Logloss: 0.411\n",
      "\n",
      "subsample: 0.8 | colsample: 0.3 with Logloss: 0.409\n",
      "\n",
      "subsample: 0.8 | colsample: 0.4 with Logloss: 0.410\n",
      "\n",
      "subsample: 0.9 | colsample: 0.1 with Logloss: 0.410\n",
      "\n",
      "subsample: 0.9 | colsample: 0.2 with Logloss: 0.410\n",
      "\n",
      "subsample: 0.9 | colsample: 0.3 with Logloss: 0.410\n",
      "\n",
      "subsample: 0.9 | colsample: 0.4 with Logloss: 0.409\n",
      "\n",
      "subsample: 1.0 | colsample: 0.1 with Logloss: 0.410\n",
      "\n",
      "subsample: 1.0 | colsample: 0.2 with Logloss: 0.411\n",
      "\n",
      "subsample: 1.0 | colsample: 0.3 with Logloss: 0.410\n",
      "\n",
      "subsample: 1.0 | colsample: 0.4 with Logloss: 0.410\n",
      "\n",
      "Best Parameters: subsample: 0.9 | colsample: 0.4 with Logloss: 0.409\n"
     ]
    }
   ],
   "source": [
    "logloss_min = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for subsample, colsample in (gridsearch_params):\n",
    "    \n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    \n",
    "    xg_cvresults = xgb.cv(params, dtrain = dm_train, num_boost_round = 100,\n",
    "                      seed = 0, nfold=10, metrics = {'logloss'}, early_stopping_rounds = 10,)\n",
    "    \n",
    "    logloss_mean = xg_cvresults['test-logloss-mean'].min()\n",
    "    \n",
    "    print(\"subsample: {} | colsample: {} with Logloss: {:.3f}\\n\".format(subsample,colsample,logloss_mean))\n",
    "    \n",
    "    if logloss_mean < logloss_min:\n",
    "        logloss_min = logloss_mean\n",
    "        best_params = (subsample, colsample)\n",
    "        \n",
    "print(\"Best Parameters: subsample: {} | colsample: {} with Logloss: {:.3f}\". format(best_params[0], \n",
    "                                                                           best_params[1], logloss_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Updating the parameters with the best values: subsample = 0.9 and colsample = 0.4\n",
    "\n",
    "params['subsample'] = 0.9\n",
    "params['colsample_bytree'] = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta: 0.3 with Logloss: 0.409\n",
      "\n",
      "eta: 0.2 with Logloss: 0.41\n",
      "\n",
      "eta: 0.1 with Logloss: 0.41\n",
      "\n",
      "eta: 0.05 with Logloss: 0.419\n",
      "\n",
      "eta: 0.01 with Logloss: 0.513\n",
      "\n",
      "eta: 0.005 with Logloss: 0.574\n",
      "\n",
      "Best Parameter: eta: 0.3 with Logloss: 0.409\n"
     ]
    }
   ],
   "source": [
    "# Parameter: eta\n",
    "\n",
    "logloss_min = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for eta in [0.3, 0.2, 0.1, 0.05, 0.01, 0.005]:\n",
    "    \n",
    "    params['eta'] = eta\n",
    "    \n",
    "    xg_cvresults = xgb.cv(params, dtrain = dm_train, num_boost_round = 100,\n",
    "                      seed = 0, nfold=10, metrics = {'logloss'}, early_stopping_rounds = 10,)\n",
    "    \n",
    "    logloss_mean = xg_cvresults['test-logloss-mean'].min()\n",
    "    print(\"eta: {} with Logloss: {:.3}\\n\".format(eta,logloss_mean))\n",
    "    \n",
    "    if logloss_mean < logloss_min:\n",
    "        logloss_min = logloss_mean\n",
    "        best_params = eta\n",
    "        \n",
    "print(\"Best Parameter: eta: {} with Logloss: {:.3f}\". format(best_params, logloss_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Updating the eta parameter with the best value\n",
    "\n",
    "params['eta'] = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting the optimum paramters\n",
    "\n",
    "params = {'colsample_bytree': 0.4,\n",
    "          'eta': 0.3,\n",
    "          'eval_metric': 'logloss',\n",
    "          'max_depth': 2,\n",
    "          'min_child_weight': 19,\n",
    "          'objective':'binary:logistic',\n",
    "          'subsample': 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-logloss:0.600401\n",
      "Will train until Test-logloss hasn't improved in 10 rounds.\n",
      "[1]\tTest-logloss:0.549328\n",
      "[2]\tTest-logloss:0.516349\n",
      "[3]\tTest-logloss:0.4893\n",
      "[4]\tTest-logloss:0.466593\n",
      "[5]\tTest-logloss:0.457725\n",
      "[6]\tTest-logloss:0.447171\n",
      "[7]\tTest-logloss:0.439201\n",
      "[8]\tTest-logloss:0.434518\n",
      "[9]\tTest-logloss:0.43136\n",
      "[10]\tTest-logloss:0.428476\n",
      "[11]\tTest-logloss:0.42519\n",
      "[12]\tTest-logloss:0.422867\n",
      "[13]\tTest-logloss:0.421699\n",
      "[14]\tTest-logloss:0.420693\n",
      "[15]\tTest-logloss:0.420601\n",
      "[16]\tTest-logloss:0.420589\n",
      "[17]\tTest-logloss:0.42018\n",
      "[18]\tTest-logloss:0.419269\n",
      "[19]\tTest-logloss:0.418866\n",
      "[20]\tTest-logloss:0.418494\n",
      "[21]\tTest-logloss:0.417789\n",
      "[22]\tTest-logloss:0.418126\n",
      "[23]\tTest-logloss:0.41787\n",
      "[24]\tTest-logloss:0.417785\n",
      "[25]\tTest-logloss:0.417646\n",
      "[26]\tTest-logloss:0.41748\n",
      "[27]\tTest-logloss:0.417536\n",
      "[28]\tTest-logloss:0.417761\n",
      "[29]\tTest-logloss:0.418046\n",
      "[30]\tTest-logloss:0.417699\n",
      "[31]\tTest-logloss:0.418235\n",
      "[32]\tTest-logloss:0.418586\n",
      "[33]\tTest-logloss:0.418454\n",
      "[34]\tTest-logloss:0.418989\n",
      "[35]\tTest-logloss:0.418331\n",
      "[36]\tTest-logloss:0.418251\n",
      "Stopping. Best iteration:\n",
      "[26]\tTest-logloss:0.41748\n",
      "\n",
      "Best Logloss: 0.417 in 27 rounds\n"
     ]
    }
   ],
   "source": [
    "# Finding the optimal number of rounds for the model with new parameters\n",
    "\n",
    "xgmodel_tuned = xgb.train(params, dtrain = dm_train, \n",
    "                          num_boost_round=100, evals=[(dm_test,\"Test\")], early_stopping_rounds=10)\n",
    "\n",
    "\n",
    "print(\"Best Logloss: {:.3f} in {} rounds\". format(xgmodel_tuned.best_score, xgmodel_tuned.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With the tuned parameters we would need 27 rounds to achieve the best result\n",
    "\n",
    "# The improvement after parameter tuning is marginal in our case.\n",
    "    # Logloss of our model decreased from 0.424 to 0.417\n",
    "# However, we were able to see how parameters can be tuned.\n",
    "\n",
    "# Here we have used only a few combination of parameters.\n",
    "# We can further improve the impact of tuning; however, doing so would be computationally more expensive.\n",
    "# More combination of parameters and wider ranges of values for each of those paramaters would have to be tested."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
